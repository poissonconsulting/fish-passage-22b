
@article{castilho_towards_2021,
	title = {Towards a pragmatic use of statistics in ecology},
	volume = {9},
	issn = {2167-8359},
	url = {https://peerj.com/articles/12090},
	doi = {10.7717/peerj.12090},
	abstract = {Although null hypothesis testing (NHT) is the primary method for analyzing data in many natural sciences, it has been increasingly criticized. Recently, approaches based on information theory (IT) have become popular and were held by many to be superior because it enables researchers to properly assess the strength of the evidence that data provide for competing hypotheses. Many studies have compared IT and NHT in the context of model selection and stepwise regression, but a systematic comparison of the most basic uses of statistics by ecologists is still lacking. We used computer simulations to compare how both approaches perform in four basic test designs (t-test, ANOVA, correlation tests, and multiple linear regression). Performance was measured by the proportion of simulated samples for which each method provided the correct conclusion (power), the proportion of detected effects with a wrong sign (S-error), and the mean ratio of the estimated effect to the true effect (M-error). We also checked if the p-value from significance tests correlated to a measure of strength of evidence, the Akaike weight. In general both methods performed equally well. The concordance is explained by the monotonic relationship between p-values and evidence weights in simple designs, which agree with analytic results. Our results show that researchers can agree on the conclusions drawn from a data set even when they are using different statistical approaches. By focusing on the practical consequences of inferences, such a pragmatic view of statistics can promote insightful dialogue among researchers on how to find a common ground from different pieces of evidence. A less dogmatic view of statistical inference can also help to broaden the debate about the role of statistics in science to the entire path that leads from a research hypothesis to a statistical hypothesis.},
	language = {en},
	urldate = {2023-08-08},
	journal = {PeerJ},
	author = {Castilho, Leonardo Braga and Prado, Paulo Inácio},
	month = sep,
	year = {2021},
	note = {Publisher: PeerJ Inc.},
	keywords = {To Read},
	pages = {e12090},
	file = {Castilho and Prado - 2021 - Towards a pragmatic use of statistics in ecology.pdf:/Users/joe/Zotero/storage/DXRTLX6G/Castilho and Prado - 2021 - Towards a pragmatic use of statistics in ecology.pdf:application/pdf},
}

@article{murtaugh_defense_2014,
	title = {In defense of \textit{{P}} values},
	volume = {95},
	issn = {0012-9658},
	url = {http://www.esajournals.org/doi/abs/10.1890/13-0590.1},
	doi = {10.1890/13-0590.1},
	language = {en},
	number = {3},
	urldate = {2014-03-24},
	journal = {Ecology},
	author = {Murtaugh, Paul A.},
	month = mar,
	year = {2014},
	keywords = {sgpd, pvalues},
	pages = {611--617},
	file = {Murtaugh - 2014 - In defense of iPi values.pdf:/Users/joe/Zotero/storage/MPV42WBX/Murtaugh - 2014 - In defense of iPi values.pdf:application/pdf},
}

@article{akaike_likelihood_1978,
	title = {On the {Likelihood} of a {Time} {Series} {Model}},
	volume = {27},
	issn = {1467-9884},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.2307/2988185},
	doi = {10.2307/2988185},
	abstract = {The conventional approach to parametric model fitting of time series is realized through the comparison of various competing models by some ad hoc criterion. Since each of the models is usually specified by the parameters determined by the information from the data, the extension of the classical concept of likelihood to this situation is not obvious. By asking the log likelihood of a model to be an unbiased estimate of the expected log likelihood of the model, a reasonable definition of the likelihood is obtained and this allows us to develop a systematic approach to parametric time series modelling. Practical utility of this approach is demonstrated by numerical examples.},
	language = {en},
	number = {3-4},
	urldate = {2023-01-28},
	journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
	author = {Akaike, Hirotugu},
	year = {1978},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.2307/2988185},
	pages = {217--235},
	file = {Snapshot:/Users/joe/Zotero/storage/VFGDB87L/2988185.html:text/html},
}

@article{bradford_using_2005,
	title = {Using confidence intervals to estimate the response of salmon populations ({Oncorhynchus} spp.) to experimental habitat alterations},
	volume = {62},
	issn = {0706-652X, 1205-7533},
	url = {http://www.nrcresearchpress.com/doi/abs/10.1139/f05-179},
	doi = {10.1139/f05-179},
	number = {12},
	journal = {Canadian Journal of Fisheries and Aquatic Sciences},
	author = {Bradford, Michael J and Korman, Josh and Higgins, Paul S},
	year = {2005},
	pages = {2716--2726}
}

@book{brooks_handbook_2011,
	address = {Boca Raton},
	title = {Handbook for {Markov} {Chain} {Monte} {Carlo}},
	isbn = {978-1-4200-7941-8},
	publisher = {Taylor \& Francis},
	editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin L. and Meng, Xiao-Li},
	year = {2011}
}

@book{burnham_model_2002,
	address = {New York, NY},
	title = {Model {Selection} and {Multimodel} {Inference}},
	isbn = {978-0-387-95364-9},
	url = {https://link.springer.com/10.1007/b97636},
	urldate = {2018-11-23},
	publisher = {Springer New York},
	author = {Burnham, Kenneth P. and Anderson, David R.},
	year = {2002},
	doi = {10.1007/b97636}
}

@article{carpenter_stan_2017,
  title = {\textit{{Stan}} : {A} {Probabilistic} {Programming} {Language}},
  volume = {76},
  issn = {1548-7660},
  url = {http://www.jstatsoft.org/v76/i01/},
  doi = {10.18637/jss.v076.i01},
  number = {1},
  journal = {Journal of Statistical Software},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017}
}

@article{chow_semantic_2019,
	title = {Semantic and {Cognitive} {Tools} to {Aid} {Statistical} {Inference}: {Replace} {Confidence} and {Significance} by {Compatibility} and {Surprise}},
	shorttitle = {Semantic and {Cognitive} {Tools} to {Aid} {Statistical} {Inference}},
	url = {http://arxiv.org/abs/1909.08579},
	abstract = {Researchers often misinterpret and misrepresent statistical outputs. This abuse has led to a large literature on modification or replacement of testing thresholds and P-values with confidence intervals, Bayes factors, and other devices. Because the core problems appear cognitive rather than statistical, we review some simple proposals to aid researchers in interpreting statistical outputs. These proposals emphasize logical and information concepts over probability, and thus may be more robust to common misinterpretations than are traditional descriptions. The latter treat statistics as referring to targeted hypotheses conditional on background assumptions. In contrast, we advise reinterpretation of P-values and interval estimates in unconditional terms, in which they describe compatibility of data with the entire set of analysis assumptions. We use the Shannon transform of the P-value \$p\$, also known as the surprisal or S-value \$s=-log(p)\$, to provide a measure of the information supplied by the testing procedure against these assumptions, and to help calibrate intuitions against simple physical experiments like coin tossing. We also advise tabulating or graphing test statistics for alternative hypotheses, and interval estimates for different percentile levels, to thwart fallacies arising from arbitrary dichotomies. We believe these simple reforms are well worth the minor effort they require.},
	language = {en},
	urldate = {2019-09-19},
	journal = {arXiv:1909.08579 [q-bio, stat]},
	author = {Chow, Zad R. and Greenland, Sander},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.08579},
	keywords = {Quantitative Biology - Quantitative Methods, Statistics - Applications, Statistics - Methodology, obsbiascomp},
	file = {Chow and Greenland - 2019 - Semantic and Cognitive Tools to Aid Statistical In.pdf:/Users/joe/Zotero/storage/Z52NF7FS/Chow and Greenland - 2019 - Semantic and Cognitive Tools to Aid Statistical In.pdf:application/pdf}
}

@article{gelman_prior_2017,
  title = {The {Prior} {Can} {Often} {Only} {Be} {Understood} in the {Context} of the {Likelihood}},
  volume = {19},
  issn = {1099-4300},
  url = {http://www.mdpi.com/1099-4300/19/10/555},
  doi = {10.3390/e19100555},
  number = {10},
  journal = {Entropy},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  year = {2017},
}

@article{greenland_living_2013,
	title = {Living with {P} {Values}: {Resurrecting} a {Bayesian} {Perspective} on {Frequentist} {Statistics}},
	volume = {24},
	issn = {1044-3983},
	shorttitle = {Living with {P} {Values}},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00001648-201301000-00009},
	doi = {10.1097/EDE.0b013e3182785741},
	language = {en},
	number = {1},
	urldate = {2014-03-24},
	journal = {Epidemiology},
	author = {Greenland, Sander and Poole, Charles},
	month = jan,
	year = {2013},
	keywords = {Bayesian course, pvalues, states-of-nature, obsbiascomp},
	pages = {62--68},
	file = {Greenland and Poole - 2013 - Living with P Values Resurrecting a Bayesian Pers.pdf:/Users/joe/Zotero/storage/3QE82TEX/Greenland and Poole - 2013 - Living with P Values Resurrecting a Bayesian Pers.pdf:application/pdf}
}

@article{greenland_valid_2019,
	title = {Valid \textit{{P}} -{Values} {Behave} {Exactly} as {They} {Should}: {Some} {Misleading} {Criticisms} of \textit{{P}} -{Values} and {Their} {Resolution} {With} \textit{{S}} -{Values}},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	shorttitle = {Valid \textit{{P}} -{Values} {Behave} {Exactly} as {They} {Should}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1529625},
	doi = {10.1080/00031305.2018.1529625},
	language = {en},
	number = {sup1},
	urldate = {2019-04-25},
	journal = {The American Statistician},
	author = {Greenland, Sander},
	month = mar,
	year = {2019},
	keywords = {pvalues, states-of-nature, obsbiascomp},
	pages = {106--114},
	file = {Greenland - 2019 - Valid iPi -Values Behave Exactly as They Shou.pdf:/Users/joe/Zotero/storage/BWBA8UPD/Greenland - 2019 - Valid iPi -Values Behave Exactly as They Shou.pdf:application/pdf}
}

@Book{kery_bayesian_2011,
  address = {Boston},
  author = {Marc Kery and Michael Schaub},
  publisher = {Academic Press},
  title = {Bayesian population analysis using {WinBUGS} : a hierarchical perspective},
  url = {http://www.vogelwarte.ch/bpa.html},
  year = {2011},
}

@article{kristensen_tmb_2016,
	title = {\textbf{{TMB}} : {Automatic} {Differentiation} and {Laplace} {Approximation}},
	volume = {70},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v70/i05/},
	doi = {10.18637/jss.v070.i05},
	language = {en},
	number = {5},
	journal = {Journal of Statistical Software},
	author = {Kristensen, Kasper and Nielsen, Anders and Berg, Casper W. and Skaug, Hans and Bell, Bradley M.},
	year = {2016}
}

@book{mcelreath_statistical_2016,
  address = {Boca Raton},
  series = {Chapman \& {Hall}/{CRC} texts in statistical science series},
  title = {Statistical rethinking: a {Bayesian} course with examples in {R} and {Stan}},
  isbn = {978-1-4822-5344-3},
  shorttitle = {Statistical rethinking},
  number = {122},
  publisher = {CRC Press/Taylor \& Francis Group},
  author = {McElreath, Richard},
  year = {2016}
}


@book{mcelreath_statistical_2020,
	address = {Boca Raton},
	edition = {2},
	series = {{CRC} texts in statistical science},
	title = {Statistical rethinking: a {Bayesian} course with examples in {R} and {Stan}},
	isbn = {978-0-367-13991-9},
	shorttitle = {Statistical rethinking},
	publisher = {Taylor and Francis, CRC Press},
	author = {McElreath, Richard},
	year = {2020}
}

@book{millar_maximum_2011,
	address = {Chichester},
	series = {Statistics in practice},
	title = {Maximum likelihood estimation and inference: with examples in {R}, {SAS}, and {ADMB}},
	isbn = {978-0-470-09482-2},
	shorttitle = {Maximum likelihood estimation and inference},
	publisher = {Wiley},
	author = {Millar, R. B.},
	year = {2011}
}

@inproceedings{plummer_jags:_2003,
	address = {Vienna, Austria},
	title = {{JAGS}: a program for analysis of {Bayesian} graphical models using {Gibbs} sampling},
	booktitle = {Proceedings of the 3rd {International} {Workshop} on {Distributed} {Statistical} {Computing} ({DSC} 2003)},
	author = {Plummer, Martyn},
	editor = {Hornik, Kurt and Leisch, Friedrich and Zeileis, Achim},
	year = {2003}
}

@article{rafi_semantic_2020,
	title = {Semantic and cognitive tools to aid statistical science: replace confidence and significance by compatibility and surprise},
	volume = {20},
	issn = {1471-2288},
	shorttitle = {Semantic and cognitive tools to aid statistical science},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-01105-9},
	doi = {10.1186/s12874-020-01105-9},
	abstract = {Background: Researchers often misinterpret and misrepresent statistical outputs. This abuse has led to a large literature on modification or replacement of testing thresholds and P-values with confidence intervals, Bayes factors, and other devices. Because the core problems appear cognitive rather than statistical, we review some simple methods to aid researchers in interpreting statistical outputs. These methods emphasize logical and information concepts over probability, and thus may be more robust to common misinterpretations than are traditional descriptions.
Methods: We use the Shannon transform of the P-value p, also known as the binary surprisal or S-value s = −log2(p), to provide a measure of the information supplied by the testing procedure, and to help calibrate intuitions against simple physical experiments like coin tossing. We also use tables or graphs of test statistics for alternative hypotheses, and interval estimates for different percentile levels, to thwart fallacies arising from arbitrary dichotomies. Finally, we reinterpret P-values and interval estimates in unconditional terms, which describe compatibility of data with the entire set of analysis assumptions. We illustrate these methods with a reanalysis of data from an existing record-based cohort study.
Conclusions: In line with other recent recommendations, we advise that teaching materials and research reports discuss P-values as measures of compatibility rather than significance, compute P-values for alternative hypotheses whenever they are computed for null hypotheses, and interpret interval estimates as showing values of high compatibility with data, rather than regions of confidence. Our recommendations emphasize cognitive devices for displaying the compatibility of the observed data with various hypotheses of interest, rather than focusing on single hypothesis tests or interval estimates. We believe these simple reforms are well worth the minor effort they require.},
	language = {en},
	number = {1},
	urldate = {2022-06-19},
	journal = {BMC Medical Research Methodology},
	author = {Rafi, Zad and Greenland, Sander},
	month = dec,
	year = {2020},
	keywords = {obsbiascomp, Quantitative Biology - Quantitative Methods, Statistics - Applications, Statistics - Methodology},
	pages = {244},
	file = {Rafi and Greenland - 2020 - Semantic and cognitive tools to aid statistical sc.pdf:/Users/joe/Zotero/storage/2KXG7YUD/Rafi and Greenland - 2020 - Semantic and cognitive tools to aid statistical sc.pdf:application/pdf},
}

@misc{r_core_team_r_2022,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2022},
}

@article{thorley_fishing_2017,
	title = {The fishing and natural mortality of large, piscivorous {Bull} {Trout} and {Rainbow} {Trout} in {Kootenay} {Lake}, {British} {Columbia} (2008–2013)},
	volume = {5},
	issn = {2167-8359},
	url = {https://peerj.com/articles/2874},
	doi = {10.7717/peerj.2874},
	journal = {PeerJ},
	author = {Thorley, Joseph L. and Andrusak, Greg F.},
	year = {2017},
	pages = {e2874}
}

@article{vehtari_practical_2017,
	title = {Practical {Bayesian} model evaluation using leave-one-out cross-validation and {WAIC}},
	volume = {27},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-016-9696-4},
	doi = {10.1007/s11222-016-9696-4},
	language = {en},
	number = {5},
	urldate = {2017-10-16},
	journal = {Statistics and Computing},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	month = sep,
	year = {2017},
	keywords = {states-of-nature},
	pages = {1413--1432},
	file = {Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf:/Users/joe/Zotero/storage/HQTYYXLG/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf:application/pdf},
}

@article{watanabe_asymptotic_2010,
	title = {Asymptotic equivalence of {Bayes} cross validation and widely applicable information criterion in singular learning theory},
	volume = {11},
	url = {http://www.jmlr.org/papers/v11/watanabe10a.html},
	number = {Dec},
	urldate = {2017-07-07},
	journal = {Journal of Machine Learning Research},
	author = {Watanabe, Sumio},
	year = {2010},
	keywords = {obsbiascomp},
	pages = {3571--3594},
	file = {Watanabe - 2010 - Asymptotic equivalence of Bayes cross validation a.pdf:/Users/joe/Zotero/storage/UJSP9F2U/Watanabe - 2010 - Asymptotic equivalence of Bayes cross validation a.pdf:application/pdf},
}

@article{watanabe_widely_2013,
	title = {A widely applicable {Bayesian} information criterion},
	volume = {14},
	url = {http://www.jmlr.org/papers/v14/watanabe13a.html},
	number = {Mar},
	urldate = {2017-10-06},
	journal = {Journal of Machine Learning Research},
	author = {Watanabe, Sumio},
	year = {2013},
	pages = {867--897},
	file = {Watanabe - 2013 - A widely applicable Bayesian information criterion.pdf:/Users/joe/Zotero/storage/RHFH93GR/Watanabe - 2013 - A widely applicable Bayesian information criterion.pdf:application/pdf},
}

@misc{morris_sub-hourly_2022,
	title = {Sub-hourly water temperature collected by {UNBC}'s northern hydrometeorology group ({NHG}) across the {Nechako} {Watershed}, 2019-2021},
	url = {https://zenodo.org/records/6426024},
	doi = {10.5281/zenodo.6426023},
	abstract = {This is a dataset of water temperature time series collected at 15 minute intervals at 24 sites across the Nechako Watershed. Data are provided in comma-delimited format with one file for each site. Each file name identifies the site location. The first column contains the date/time (UTC) in the format MM/DD/YEAR HH:MM. The second column contains the corresponding water temperature in degrees Celsius to two decimals. The third column contains a recommended flag for data quality, with "P" representing a "pass", "F" denoting a "fail", and "B" denoting "backwater conditions" with the likely presence of ice and below freezing temperatures. Additional issues encountered at specific sites are identified in the attached "read me" file along with basic metadata (site coordinates, elevation and period of record). A map of the sites is also attached to depict their locations across the Nechako Watershed.},
	urldate = {2024-07-08},
	author = {Morris, Jeremy and Gilbert, Derek and Kaveney, Anna and Déry, Stephen},
	year = {2022},
}


@misc{munoz_sabater_era5-land_2019,
	title = {{ERA5}-{Land} hourly data from 1950 to present},
	url = {https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview},
	doi = {10.24381/cds.e2161bac},
	abstract = {ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution compared to ERA5. ERA5-Land has been produced by replaying the land component of the ECMWF ERA5 climate reanalysis. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset using the laws of physics. Reanalysis produces data that goes several decades back in time, providing an accurate description of the climate of the past.

ERA5-Land uses as input to control the simulated land fields ERA5 atmospheric variables, such as air temperature and air humidity. This is called the atmospheric forcing. Without the constraint of the atmospheric forcing, the model-based estimates can rapidly deviate from reality. Therefore, while observations are not directly used in the production of ERA5-Land, they have an indirect influence through the atmospheric forcing used to run the simulation. In addition, the input air temperature, air humidity and pressure used to run ERA5-Land are corrected to account for the altitude difference between the grid of the forcing and the higher resolution grid of ERA5-Land. This correction is called 'lapse rate correction'.

The ERA5-Land dataset, as any other simulation, provides estimates which have some degree of uncertainty. Numerical models can only provide a more or less accurate representation of the real physical processes governing different components of the Earth System. In general, the uncertainty of model estimates grows as we go back in time, because the number of observations available to create a good quality atmospheric forcing is lower. ERA5-land parameter fields can currently be used in combination with the uncertainty of the equivalent ERA5 fields.

The temporal and spatial resolutions of ERA5-Land makes this dataset very useful for all kind of land surface applications such as flood or drought forecasting. The temporal and spatial resolution of this dataset, the period covered in time, as well as the fixed grid used for the data distribution at any period enables decisions makers, businesses and individuals to access and use more accurate information on land states.},
	urldate = {2024-07-08},
	publisher = {Copernicus Climate Change Service (C3S) Climate Data Store (CDS)},
	author = {Muñoz Sabater, J.},
	year = {2019},
}

@misc{pacific_climate_impacts_consortium_university_of_victoria_gridded_2020,
	title = {Gridded {Hydrologic} {Model} {Output}},
	url = {https://data.pacificclimate.org/portal/hydro_model_out/map/},
	abstract = {The Gridded Hydrologic Model Output page provides access to gridded, 1/16-degree (roughly 30 km2 at the latitudes covered) projections of hydrologic states and fluxes for three watersheds that originate in British Columbia, Canada; the Peace, Fraser and Columbia. Data were simulated using an upgraded version of the Variable Infiltration Capacity (VIC-GL) model, reconfigured to couple with an external dynamic glacier model (Schnorbus, in prep). Model set-up and deployment is described in Schnorbus (in prep).},
	urldate = {2024-07-08},
	author = {Pacific Climate Impacts Consortium, University of Victoria},
	month = jan,
	year = {2020},
}


@article{santos-fernandez_bayesian_2022,
	title = {Bayesian spatio-temporal models for stream networks},
	volume = {170},
	issn = {01679473},
	url = {http://arxiv.org/abs/2103.03538},
	doi = {10.1016/j.csda.2022.107446},
	abstract = {Spatio-temporal models are widely used in many research areas including ecology. The recent proliferation of the use of in-situ sensors in streams and rivers supports space-time water quality modelling and monitoring in near real-time. A new family of spatio-temporal models is introduced. These models incorporate spatial dependence using stream distance while temporal autocorrelation is captured using vector autoregression approaches. Several variations of these novel models are proposed using a Bayesian framework. The results show that our proposed models perform well using spatio-temporal data collected from real stream networks, particularly in terms of out-of-sample RMSPE. This is illustrated considering a case study of water temperature data in the northwestern United States.},
	language = {en},
	urldate = {2024-07-08},
	journal = {Computational Statistics \& Data Analysis},
	author = {Santos-Fernandez, Edgar and Hoef, Jay M. Ver and Peterson, Erin E. and McGree, James and Isaak, Daniel and Mengersen, Kerrie},
	month = jun,
	year = {2022},
	note = {arXiv:2103.03538 [stat]},
	keywords = {Statistics - Applications, Statistics - Methodology},
	pages = {107446},
	file = {Santos-Fernandez et al. - 2022 - Bayesian spatio-temporal models for stream network.pdf:/Users/nicolehill/Zotero/storage/24R975W8/Santos-Fernandez et al. - 2022 - Bayesian spatio-temporal models for stream network.pdf:application/pdf},
}

@article{peterson_mixedmodel_2010,
	title = {A mixed‐model moving‐average approach to geostatistical modeling in stream networks},
	volume = {91},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0012-9658, 1939-9170},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/10.1890/08-1668.1},
	doi = {10.1890/08-1668.1},
	abstract = {Spatial autocorrelation is an intrinsic characteristic in freshwater stream environments where nested watersheds and ﬂow connectivity may produce patterns that are not captured by Euclidean distance. Yet, many common autocovariance functions used in geostatistical models are statistically invalid when Euclidean distance is replaced with hydrologic distance. We use simple worked examples to illustrate a recently developed moving-average approach used to construct two types of valid autocovariance models that are based on hydrologic distances. These models were designed to represent the spatial conﬁguration, longitudinal connectivity, discharge, and ﬂow direction in a stream network. They also exhibit a different covariance structure than Euclidean models and represent a true difference in the way that spatial relationships are represented. Nevertheless, the multi-scale complexities of stream environments may not be fully captured using a model based on one covariance structure. We advocate using a variance component approach, which allows a mixture of autocovariance models (Euclidean and stream models) to be incorporated into a single geostatistical model. As an example, we ﬁt and compare ‘‘mixed models,’’ based on multiple covariance structures, for a biological indicator. The mixed model proves to be a ﬂexible approach because many sources of information can be incorporated into a single model.},
	language = {en},
	number = {3},
	urldate = {2024-07-08},
	journal = {Ecology},
	author = {Peterson, Erin E. and Hoef, Jay M. Ver},
	month = mar,
	year = {2010},
	pages = {644--651},
	file = {Peterson and Hoef - 2010 - A mixed‐model moving‐average approach to geostatis.pdf:/Users/nicolehill/Zotero/storage/DJX5HRE8/Peterson and Hoef - 2010 - A mixed‐model moving‐average approach to geostatis.pdf:application/pdf},
}

@article{ver_hoef_moving_2010,
	title = {A {Moving} {Average} {Approach} for {Spatial} {Statistical} {Models} of {Stream} {Networks}},
	volume = {105},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1198/jasa.2009.ap08248},
	doi = {10.1198/jasa.2009.ap08248},
	language = {en},
	number = {489},
	urldate = {2024-07-08},
	journal = {Journal of the American Statistical Association},
	author = {Ver Hoef, Jay M. and Peterson, Erin E.},
	month = mar,
	year = {2010},
	pages = {6--18},
	file = {Ver Hoef and Peterson - 2010 - A Moving Average Approach for Spatial Statistical .pdf:/Users/nicolehill/Zotero/storage/C69666T7/Ver Hoef and Peterson - 2010 - A Moving Average Approach for Spatial Statistical .pdf:application/pdf},
}


@article{mohseni_nonlinear_1998,
	title = {A nonlinear regression model for weekly stream temperatures},
	volume = {34},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0043-1397, 1944-7973},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/98WR01877},
	doi = {10.1029/98WR01877},
	abstract = {To estimateweeklystreamtemperaturesneededfor fishhabitat evaluation throughoutan annualcycle,a four-parameter,nonlinearfunctionof weeklyair temperatureswasused.The regressionfunctionwasdevelopedseparatelyfor the warming seasonand the coolingseasonto take heat storageeffects(hysteresisi)nto account. Regressionfunctionswere developedfor streamtemperaturesrecordedover a 3-year period(1978-1980) at 584 U.S. GeologicaSl urvey(USGS) gagingstationsin the contiguousUnited States.Representativeair temperatureswere obtainedfrom the closest of 197weather stations.The distancebetweena streamgagingstationand the correspondinwg eatherstationwasfrom 1.4 to 244 km. Thesedistancesdid not havea significanet ffecton the goodnessof fit. The regressionmodelfitted the weeklystream temperaturesat 573 streamgagingstations(98\% of all recordsused)with a coefficientof determinationlargerthan 0.7. For 491 records(84\% of all gagingstations)the coefficient was{\textgreater}0.9. At 56 gagingstations(10\% of all recordsused),estimatedmaximumstream temperatureswere smallerthan at leastfour weeklystreamtemperaturesrecordedfor the periodof study.Consequentlyt,he modelis deemedsuccessfullaypplicable(with 99\% confidencet)o more than 89\% of the streamgagingstationsT. he averagecoefficientof determinationof the streamtemperatureprojectionfor thesestationsis 0.93 \_ 0.01.},
	language = {en},
	number = {10},
	urldate = {2024-07-08},
	journal = {Water Resources Research},
	author = {Mohseni, Omid and Stefan, Heinz G. and Erickson, Troy R.},
	month = oct,
	year = {1998},
	pages = {2685--2692},
	file = {Mohseni et al. - 1998 - A nonlinear regression model for weekly stream tem.pdf:/Users/nicolehill/Zotero/storage/ECY5BY2P/Mohseni et al. - 1998 - A nonlinear regression model for weekly stream tem.pdf:application/pdf},
}


@article{coleman_cold_2007,
	title = {Cold {Summer} {Temperature} {Limits} {Recruitment} of {Age}-0 {Cutthroat} {Trout} in {High}-{Elevation} {Colorado} {Streams}},
	volume = {136},
	issn = {0002-8487, 1548-8659},
	url = {http://www.tandfonline.com/doi/abs/10.1577/T05-244.1},
	doi = {10.1577/T05-244.1},
	number = {5},
	urldate = {2012-07-24},
	journal = {Transactions of the American Fisheries Society},
	author = {Coleman, Mark A. and Fausch, Kurt D.},
	month = sep,
	year = {2007},
	keywords = {evaluation-of-cause, stock-productivity, energetics},
	pages = {1231--1244},
	file = {Coleman and Fausch - 2007 - Cold Summer Temperature Limits Recruitment of Age-.pdf:/Users/nicolehill/Zotero/storage/SP7QFAFA/Coleman and Fausch - 2007 - Cold Summer Temperature Limits Recruitment of Age-.pdf:application/pdf},
}


@article{gilbert_sub-hourly_2022,
	title = {Sub-hourly water temperature data collected across the {Nechako} {Watershed}, 2019-2021},
	volume = {43},
	issn = {23523409},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352340922006229},
	doi = {10.1016/j.dib.2022.108425},
	language = {en},
	urldate = {2024-07-08},
	journal = {Data in Brief},
	author = {Gilbert, Derek E. and Morris, Jeremy E. and Kaveney, Anna R. and Déry, Stephen J.},
	month = aug,
	year = {2022},
	pages = {108425},
	file = {Gilbert et al. - 2022 - Sub-hourly water temperature data collected across.pdf:/Users/nicolehill/Zotero/storage/UPSYETE6/Gilbert et al. - 2022 - Sub-hourly water temperature data collected across.pdf:application/pdf},
}

